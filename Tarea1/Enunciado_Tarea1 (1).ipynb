{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1aPHri9-tD"
      },
      "source": [
        "<center><img src=\"data:image/png;base64,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\" title=\"Title text\" /></center>\n",
        "\n",
        "\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477/577 Redes Neuronales Artificiales - 2022-2 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 1  </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "* Manipulaciones en pandas y numpy, imputación de datos y preprocesamientos\n",
        "* Redes Densas Feed Forward\n",
        "* Regularización y Dropout\n",
        "* Vanishing Gradient\n",
        "* Learn Rate Decay\n",
        "* Optimizadores\n",
        "\n",
        "\n",
        "**Formalidades**  \n",
        "* Equipos de trabajo de 3 personas (*Los estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
        "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos), se penalizará fuertemente ausencia de comentarios, explicaciones de gráficos, _etc_. Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
        "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
        "* Formato de entrega: envı́o de link del repositorio en _Github_, al correo electrónico de los ayudantes (<maryon.morales@sansano.usm.cl>, <sebastian.sanchezl@sansano.usm.cl>), en copia al profesor (<cvalle@inf.utfsm.cl>). Especificar el siguiente asunto: [INF-395/477/577-2022-2 Tarea 1]. Invitar como colaborador a los usuarios de github \"ssanchezl\" y \"maryonmorales\" para poder acceder al repositorio en caso de ser privado.\n",
        "\n",
        "* Fecha de presentaciones 07 de Octubre, en horario de clases.\n",
        "* Fecha de entrega: 08 de Octubre. Hora límite de entrega: 12:00 p.m. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail igualmente.  \n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "\n",
        "* 1 - Redes Feed Forward para predicción de diabetes.\n",
        "\n",
        "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo, solo son guias y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
        "Recuerden intercalar su código con *comentarios* en celdas _Markdown_, con los comentarios de la pregunta y con cualquier análisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. *No respondan las preguntas en comentarios en el código*.\n",
        "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará tanto la elección en si. En cambio la argumentación detrás de la elección será lo más ponderado.\n",
        "Si algún modelo se demora demasiado en correr en su máquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, incluso con la opción de aceleración con GPU (particularmente útil para los modelos más grandes), esto puede ser relevante para las máquinas más lentas al momento de realizar exploraciones con _K-folds_ o las redes más grandes. Existe también la posibilidad de utilizar _Google Cloud Plataform_ o _Amazon Web Service_, donde tienen máquinas aceleradas con GPU; maquinas ya configuradas para _deep leraning_ pueden encontrarse en el _Marketplace_ de cada proveedor de servicios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnyDQ-3kdlTZ"
      },
      "source": [
        "# 1 - Redes Feed Forward para predicción de diabetes\n",
        "\n",
        "De las redes neuronales artificiales más simples se encuentran las redes densas o Feed Forward, donde todas las neuronas de una capa estan conectadas a todos los inputs y envían su señal de activación a todas las neuronas de la siguiente capa. Estas redes, si bien son las más simples, suelen tener desempeños bastante buenos, y en muchas aplicaciones reales son utilizadas, ya sea por si solas o en combinación con otros modelos. Además, son las redes donde más facil se pueden observar muchos de los fenómenos que se han descubierto a lo largo de los años de desarrollo de esta area del conocimiento, tanto por ser de las redes vigentes más antiguas y por su estructura relativamente simple. En esta primera parte de la tarea exploraremos las redes densas y algunos de sus hiperparámetros más relevantes como la profundidad, el número de unidades; estudiaremos también algunos métodos de regularización y evidenciaremos el problema del vanishing gradient y el exploding gradient, viendo también algunos optimizadores existentes.\n",
        "\n",
        "Para realizar esto, utilizaremos una base de datos de variables médicas predictoras de la diabetes en mujeres y la variable objetivo (presencia o ausencia de diabetes), la cual se encuentra disponible en Kaggle, en la siguiente URL: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database. Las variables predictoras incluyen el número de embarazos que ha tenido la paciente, su IMC, el nivel de insulina, la edad, entre otros. Nuesta tarea durante esta pregunta será predecir si la persona tiene o no de diabetes a partir de algunas de las otras variables presentes en el dataset. Para esto primero deberán explorar los atributos del dataset, imputar los valores que falten o eliminarlos en caso que estime conveniente, y luego preprocesar los datos de forma eficiente para que así puedan ser utilizados por una red neuronal. Una vez separados los datos de entrenamiento, validación y test, procederemos a entrenar diferentes modelos, comparandolos y evaluando sus desempeños."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvDv0hugEGi0"
      },
      "source": [
        "## 1.a Carga de datos y primeros análisis\n",
        "Para cargar los datos, puede descargarlos desde el link de Kaggle, o puede descargarlos desde su jupyter nootebok como muestra el código a continuación. Para obtener más información acerca de como descargar datasets directamente desde la API de Kaggle puede dirigirse a la documentación que se encuentra en el siguiente link: https://github.com/Kaggle/kaggle-api#download-dataset-files. Para usar la API de Kaggle dentro de Google Colab puede serle de utilidad el siguiente link: https://galhever.medium.com/how-to-import-data-from-kaggle-to-google-colab-8160caa11e2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJChEsDZ5Pig"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d uciml/pima-indians-diabetes-database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bc7svRyH_Gf"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/pima-indians-diabetes-database.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtpxQvPnHr0L"
      },
      "source": [
        "Luego de descomprimir el archivo descargado cargue los datos en un *Dataframe* como muestra el código. Explore superficialmente los datos utilizando los metodos .head, .describe o .info del *Dataframe*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avgT6Pg0H0gJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBqtnmtJPIF"
      },
      "source": [
        "Identifique y comente sobre las características de la variable objetivo (target) que sean relevantes para el problema. ¿Que puede decir acerca de la distribución de las clases?, ¿Están balanceadas? Explique usando gráficos que le parezcan pertinentes para representar el balance de clases. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pItTJIUvPwuQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos_diab = df[df['Outcome'] != 0]...\n",
        "neg_diab = df[df['Outcome'] == 0]...\n",
        "\n",
        "plt.title(\"Conteo de la variable Outcome\")\n",
        "plt.hist(pos_diab, label='Positivo')\n",
        "plt.hist(pos_diab, label='Negativo')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ihfw0xsPLW1"
      },
      "source": [
        "¿Qué puede observar de los datos, tiene sentido que algunos valores de ciertas variables predictoras tengan valor 0?, \n",
        "\n",
        "Identifique cuales son las columnas con datos faltantes que fueron imputadas con el valor 0. ¿Tiene sentido estos atributos tengan valores 0? Investigue el rango de valores que puede tomar cada atributo en el dataset, y comente sus principales características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXqGF7raZTLo"
      },
      "source": [
        "## 1.b Train Test Split\n",
        "\n",
        "En esta pregunta nos ocuparemos de separar el dataset en los conjuntos de entrenamiento, validación y test y estandarizar los datos. Para esto puede utilizar la librería sklearn, en particular la función `train_test_split`. Para esto separe primero el dataset en  $X$  e  $Y$. Luego separe los datos considerando un  70%  de ellos para entrenamiento, un  20%  para validación y un  10%  para test. ¿Qué estamos tratando de representar en esta separación en conjuntos de entrenamiento, validación y test?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii8CDG9OJzYy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# . . . \n",
        "\n",
        "X = df.drop(columns=['Outcome'])\n",
        "y = ...\n",
        "\n",
        "X_tr, X_test, y_tr, y_test = train_test_split(\n",
        "     X, y, test_size=...)\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = ...\n",
        "\n",
        "# . . .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdEoLMJ1c38a"
      },
      "source": [
        "## 1.c Valores faltantes e imputación\n",
        "\n",
        "Tomando en cuenta solamente el conjunto de entrenamiento, considere los valores imputados con 0 que encontró en la pregunta 1.a y reemplacelos por `NaN`, para esto utilice el método `replace`. Cuente cuantos datos faltantes hay por cada atributo y grafíque. Cree 3 conjuntos de entrenamiento nuevos a partir del resultado de reemplazar con `NaN`:\n",
        "\n",
        "1.   Conserve el conjunto de entrenamiento original intacto: $X_o$\n",
        "2.   Reemplace los valores faltantes de cada columna por la media de estos: $X_1$\n",
        "3.   Reemplace los valores faltantes de cada columna por la mediana de estos: $X_2$\n",
        "4.   Reemplace los valores faltantes de cada columna utilizando el método MICE [1][2]: $X_3$\n",
        "\n",
        "Responda las siguientes preguntas:\n",
        "\n",
        "*   ¿Qué es la imputación de datos?\n",
        "*   ¿Cuáles son las ventajas y desventajas de los 3 métodos recién utilizados versus sin imputar ($X_o$)?\n",
        "*   ¿Qué se necesita para ejecutar cada uno de los 3 métodos de imputación de datos?\n",
        "*   ¿Qué puede decir de los conjuntos resultantes?¿Resuelven el problema de los datos faltantes?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[1] https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.169.5745&rep=rep1&type=pdf\n",
        "\n",
        "[2] https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html?highlight=mice\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MCLuHEzhEHI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_tr[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = X_tr[['Glucose',\n",
        "'BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
        "\n",
        "X1 = X_tr.mean()\n",
        "X2 = X_tr.median()\n",
        "X3 = ...\n",
        "# . . . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrGNkhQlY8v"
      },
      "source": [
        "## 1.d Estandarización\n",
        "\n",
        "`Nota:` A menos que se indique explícitamente lo contrario, en esta y las siguientes preguntas realice los siguientes procedimientos y entrene las redes considerando como conjunto de entrenamiento cada $X \\in \\{X_o, X_1, X_2, X_3\\}$ obtenido en la imputación anterior y comente las diferencias que observa en los desempeños de sus redes.\n",
        "\n",
        "Ajuste los scalers con los datos de entrenamiento y transforme los datos para cada conjunto obtenido en la pregunta anterior.\n",
        "\n",
        "- ¿Qué operación matemática realiza `StandarScaler` al momento de tranformar los datos? \n",
        "- ¿Por qué debemos transformar los datos de validación y de test con el _scaler_ ajustado a los datos de entrenamiento? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hcDWUA5le7u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StandardScaler\n",
        "\n",
        "scaler_xo = StandardScaler()\n",
        "scaler_xo.fit(X_tr)\n",
        "x_tr_o = scaler_xo.transform(X_tr)\n",
        "x_val_o = scaler_xo.transform(X_val)\n",
        "\n",
        "scaler_x1 = StandardScaler()\n",
        "scaler_x1.fit(X_tr)\n",
        "x_tr_1 = scaler_x1.transform(X_tr)\n",
        "x_val_1 = scaler_x1.transform(X_val)\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXSQWk9Ovv-3"
      },
      "source": [
        "## 1.e Primera Red\n",
        "En esta pregunta construiremos y entrenaremos una primera red neuronal. Para esto utilizaremos la librería keras que se ocupa de crear, compilar y entrenar los modelos de manera simple. Keras se encargará por lo tanto de crear los modelos y al momento de compilarlos se instanciarán estos en una sesión de TensorFlow. \n",
        "\n",
        "Esta primera red será una red de una capa oculta con $256$ neuronas, activación ReLu. Para esta red y todas las demas utilizaremos la función de pérdida _Binary Cross Entropy_ ¿Porqué se ocupa esta función de pérdida?¿Qué función de activación se utiliza para la capa de salida en este tipo de problemas?¿Cuántas neuronas para la capa de salida?. Para entrenar esta primera red utilizaremos Gradiente Descendente Estocástico con un _Learn Rate_ de 0.002. Finalmente entrenaremos esta red por unas 20 _epochs_.\n",
        "\n",
        "Construya la red basandose en el siguiente código y en la documentación de keras. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKXWgcNQwZ8f"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "ANN = Sequential()\n",
        "\n",
        "# Hidden Layer\n",
        "ANN.add(\n",
        "    Dense(\n",
        "        units = # n units, \n",
        "        activation = 'relu'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Output Layer\n",
        "ANN.add(Dense\n",
        "       units = # dimension of Output... ,\n",
        "       activation=\n",
        "       )\n",
        "\n",
        "ANN.compile(\n",
        "    optimizer=SGD(# . . .  , \n",
        "    loss='binary_crossentropy')\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIyGBE4xMFis"
      },
      "source": [
        "Utilice el método `.summary` para ver el número de parámetros de su red y los tamaños de cada capa. \n",
        "\n",
        "Explique el número de parámetros presentes en esta red, es decir: ¿Cómo a partir de la dimensión del _Input_ y el número de neuronas obtenemos ese número de parámetros?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obOh3pHuPQ5g"
      },
      "outputs": [],
      "source": [
        "ANN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCB8gKjyPVQo"
      },
      "source": [
        "Entrene la red por 20 _epochs_, guardando el `history` que retorna el metodo `.fit`.\n",
        "\n",
        "Grafique como varian los errores de validación y de entrenamiento a lo largo de las _epochs_. Comente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlvwIPWOPaHu"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_tr, y_tr, epochs=20, validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzf2YikAPgMz"
      },
      "source": [
        "Cree y entrene nuevamente la red, esta vez cambiando el _learn rate_ utilizado para el SGD. Pruebe a lo menos un valor mayor y un valor menor al elegido anteriormente. Note que para valores mayores al propuesto puede comenzar a observar fenómeno de divergencia, por lo cual es recomendable agregarle a la red un _callback_, es decir una función que verifica estados y comportamientos de la red mientras se entrena, en particular `TerminateOnNaN`, el cual interrumpirá el proceso de entrenamiento si encuentra un valor NaN. \n",
        "\n",
        "Grafique el comportamiento de los errores de validación y entrenamiento y comente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URWA5gkkQJr-"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import TerminateOnNaN\n",
        "\n",
        "# . . . \n",
        "\n",
        "history = ANN.fit( # . . .\n",
        "         callbacks=[TerminateOnNaN]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXYySJsrQcOV"
      },
      "source": [
        "## 1.f Activación y regularizadores $l1$ $l2$\n",
        "En esta pregunta se les propone explorar distintas funciones de activación y de regularización. En ambos casos debe entrenar la misma red entrenada anteriormente utilizando gradiente descendente estocástico con algun _learn rate_ que le parezca adecuado luego de la exploración en la pregunta anterior. \n",
        "\n",
        "* Para explorar distintas funciones de activación, cambie la activación de la capa oculta sucesivamente por: tangente hiperbólica, _Leaky ReLu_, sigmoidea y lineal. Para esto puede basarse en el código presentado abajo y la documentación de keras. Para la activación _Leaky ReLu_ pruebe cambiar el parámetro de la red. Describa sus resultados y si observa diferencias entre las redes. \n",
        "\n",
        "* Seleccione la función de activación que mejor resultados le dió y agregue regularización $l1$ a la capa oculta, luego pruebe con $l2$. Pruebe cambiar la tasa de regularización, reportando sus resultados. ¿Qué ocurre si la regularización es muy alta o muy baja? Una vez satisfecho con una tasa de regularización, aplique la regularización a la capa de salida y luego a ambas capas. \n",
        "\n",
        "¿Para qué se usan activaciones no lineales? ¿Le parece buena opción la activación sigmoidea para la capa oculta?\n",
        "\n",
        "¿Cual es la intención de la regularización en general? En particular, ¿Que restricción implicita imponen las regularizaciones $l$1 o $l$2 sobre los pesos de la capa en la cual se aplican? Apoyese de ecuaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzaQJtDCU53D"
      },
      "outputs": [],
      "source": [
        "# activations\n",
        "from keras.layers import LeakyReLU\n",
        "model.add(Dense( # . . . ))\n",
        "model.add(LeakyReLU())\n",
        "    \n",
        "# regularizer\n",
        "from keras.regularizers import l1, l2\n",
        "model.add(\n",
        "    Dense( # . . .\n",
        "          activity_regularizer=l2(0.001)\n",
        "         )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRg9SupLVBO0"
      },
      "source": [
        "## 1.g Exploración del Número de neuronas\n",
        "\n",
        "Ahora probaremos cambiando el número de neuronas en la capa oculta. Para esto, entrene la red con los hiperparámetros que estimen conveniente luego de la pregunta anterior, variando el numero de neuronas. Deben explorar a lo menos 10 número de neuronas distintos. Una recomendación sería por ejemplo explorar numero de neuronas en potencias de 2. \n",
        "\n",
        "Para cada red entrenada, recuperen el mejor error de validación y el error de entrenamiento en la _epoch_ donde se obtuvo tal error de validación. Grafique como se comportan ambos errores a medida crece el número de neuronas y comente. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJV-oySgVPLt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train_error, val_error = [], []\n",
        "\n",
        "for n_units in [2**(k), 2**(k+1), 2**(k+2), ..., 2**(k+9)]\n",
        "    \n",
        "    # do model \n",
        "    \n",
        "    # train model \n",
        "    \n",
        "    val_error = min(history.history['val_loss'])\n",
        "    train_error = history.history['loss'][np.argmin(history.history['val_loss'])] \n",
        "    # for instance\n",
        "    \n",
        "# . . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlrljePYWqvt"
      },
      "source": [
        "## 1.h Dropout\n",
        "Como seguramente constataron en la pregunta anterior, un numero demasiado grande de parámetros en el modelo puede llevarnos a observar el fenomeno de _overfitting_. Una aproximación a este fenómeno que ha dado excelente resultado en redes neuronales es el método _dropout_, donde estocásticamente se desactivan una fracción de las neuronas al momento del entrenamiento, así efectivamente reduciendo el tamaño del modelo que se entrena en cada iteración e implicitamente obteniendo modelos más robustos por el simple hecho que al momento de entrenar nunca se entrena el \"mismo\" modelo. \n",
        "\n",
        "Según lo aprendido en el ramo, ¿en qué consiste el fenómeno de _overfitting_? ¿Por qué modelos más grandes suelen presentar el fenómeno? \n",
        "\n",
        "Entrene la mejor red obtenida en la pregunta anterior agregando una capa de _Dropout_ con parámetro $0.5$ inmediatamente luego de la capa oculta. Repita luego el proceso con una red con el doble de neuronas. Note que el agregar una capa _dropout_ hará que la red entrene más lento, por lo cual es recomendable aumentar el numero de _epochs_ para entrenar la red a completitud. \n",
        "\n",
        "¿Qué observa al agregar _dropout_? Comente y compare con sus resultados anteriores. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1CvZEViWrT-"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# . . . \n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiZNtjhfW-gF"
      },
      "source": [
        "## 1.i Learning Rate Decay\n",
        "Ahora entrenaremos un modelo manejando manualmente el _learn rate_. Para esto utilizaremos el _callback_ `LearningRateScheduler`. Este _callback_ nos permitirá implementar una función que maneje el _learn rate_ de nuestro modelo. \n",
        "\n",
        "Escriba una función que reciba la epoca actual y retorne un _learn rate_ lr. El lr inicial debe ser igual o mayor a alguno que haya dado buenos resultados en las preguntas anteriores. La función debe dividir por 2 el lr cada 10 _epochs_. Además ponga como restricción que el lr no debe ser menor a $5\\times 10^{-5}$, es decir si el valor obtenido es menor a  $5\\times 10^{-5}$, la función retorna  $5\\times 10^{-5}$.\n",
        "\n",
        "Entrene su red preferida de las preguntas anteriores con esta modificación, grafique los errores a lo largo del entrenamiento y comente. Según lo visto en el ramo, ¿por qué podría ser util disminuir el _learn rate_ a medida se avanza en el aprendizaje de la red?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-lO6ZS4XPT1"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def step_decay(epoch):\n",
        "    \n",
        "    \n",
        "    return lr\n",
        "\n",
        "schedule = LearningRateScheduler(step_decay)\n",
        "\n",
        "# model. # . . . \n",
        "\n",
        "model.fit(# . . .\n",
        "        callbacks=[schedule])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgTWLKGFXjHi"
      },
      "source": [
        "## 1.j Vanishing Gradient\n",
        "\n",
        "`Nota:` para esta y las siguientes preguntas solo considere el mejor conjunto de entrenamiento obtenidos a partir de la imputación, es decir, escoja el $X \\in \\{X_1, X_2, X_3\\}$ con el que mejores resultados haya obtenido hasta ahora.\n",
        "\n",
        "El fenómeno del _vanishing gradient_ es el rápido decaimiento del paso de _Backpropagation_ al avanzar por las capas. A lo largo de la tarea solo hemos entrenado capas con una red oculta, de igual forma que la comunidad cientifica realizo por largo tiempo, por el problema del _vanishing gradient_ y por el teorema de aproximación universal que resumidamente demuestra que una red de una sola capa puede aproximar una amplia familia de funciones. \n",
        "\n",
        "En esta pregunta entrenaremos una red neuronal profunda sin implementar ninguno de los dispositivos que permiten hoy en día sortear el problema del _vanishing gradient_, para ponerlo en evidencia. Para esto construya una red con 6 capas ocultas, con la siguiente lista de numero de neuronas: $256$ $256$ $128$ $128$ $32$ y $32$, o con valores similares. De tal manera obtendrá un valor de parámetros relativamente comparable a los valores utilizados en las primeras redes. \n",
        "\n",
        "Grafique un histograma con los pesos de las 6 capas densas de la red sin entrenar, entrenela a completitud con el método que estime conveniente y luego grafique nuevamente los histogramas para las 6 capas. Comente lo que observa. \n",
        "\n",
        "Luego, pruebe cambiar la inizialización de los pesos de la capa densa, puede revisar la documentación de keras para ver las opciones existentes a parte de `glorot_uniform` por defecto. ¿Se logra solucionar el problema? \n",
        "\n",
        "Por último, pruebe aumentar la tasa de aprendizaje para ver si logra hacer que el paso de _backpropagation_ alcance las capas que anteriormente no se entrenaban. ¿Qué observa en este caso? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGVS1TjVXkY2"
      },
      "outputs": [],
      "source": [
        "# . . .\n",
        "\n",
        "layer_kernel_weights = model.get_layer(index=i).get_weights()[0]\n",
        "layer_bias_weight = model.get_layer(index=i).get_weights()[1]\n",
        "# for one layer\n",
        "# you can also name your layers and call them by their names if it's less confusing\n",
        "\n",
        "# . . . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xzSDda3X54n"
      },
      "source": [
        "## 1.k Batch Normalization\n",
        "\n",
        "Una manera propuesta de mejorar los desempeños de las redes es Batch Normalization. Entrene nuevamente su red preferida de la pregunta anterior, agregando capas de _Batch Normalization_ antes de cada función de activación. Comente sus resultados. Luego pruebe agregando capas de _Batch Normalization_ después de cada función de activación.\n",
        "\n",
        "¿Qué realiza _Batch Normalization_ en términos matemáticos?. En términos de aprendizaje, ¿Qué evita la utilización de _Batch Normalization_?\n",
        "\n",
        "¿Mejoran los desempeños de la red agregando _Batch Normalization_?¿Existe diferencias entre una capa de _Batch Normalization_ justo antes o justo después de la función de activación en términos de aprendizaje? Discuta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsaYTmuWYHer"
      },
      "outputs": [],
      "source": [
        "# . . .\n",
        "generator_net.add(Dense(...))\n",
        "generator_net.add(BatchNormalization())\n",
        "generator_net.add(LeakyReLU())\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuJPFehRXsOh"
      },
      "source": [
        "## 1.l Otros Optimizadores\n",
        "\n",
        "Utilizando la arquitectura de red que mejor se haya desempeñado a lo largo de la tarea, entrene esta red utilizando un optimizador distinto al gradiente descendente estocástico. Pruebe al menos 2 optimizadores implementados en keras (puede utilizar Adam, AdaGrad, AdaDelta, RMSprop, entre otros), también puede probar modificando los parámetros que no hemos utilizado del gradiente descendente estocástico (momentum, momentum de Nesterov...).\n",
        "\n",
        "Note que por las inicializaciones por defecto de los pesos de las capas y la naturaleza de los datos en cuestión, puede ocurrir que para los valores defecto de algunos optimizadores la red diverga en las primeras iteraciones. Para fijar los parámeros de los optimizadores debe importarlos desde `keras.optimizers` y pasar el objeto con los parámetros deseados al método `.compile` de su modelo. En cambio si con los valores usuales basta, algunos optimizadores pueden pasarse como `string` a `.compile`.\n",
        "\n",
        "Compare como se desempeñan estos optimizadores con la versión utilizada anteriormente, considerando los tiempos de entrenamiento y el desempeño final alcanzado. Apoyese de gráficos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgOhV-HxXtvm"
      },
      "outputs": [],
      "source": [
        "# . . .\n",
        "\n",
        "opt = Adam(lr=0.0004, decay=1e-10, ...)\n",
        "ANN.compile(loss='binary_crossentropy', optimizer = optimizer_discriminator, metrics=['accuracy'])\n",
        "\n",
        "# . . ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13aG8_EkXyxV"
      },
      "source": [
        "## 1.m Testing \n",
        "\n",
        "Finalmente, luego de entrenar todos estos modelos estamos en condiciones de probar que tan bien fue nuestro desempeño. Para esto utilice el modelo en el cual obtuvo el mejor desempeño en validación y calcule el error de la predicción realizada sobre el _Test set_. Puede utilizar el metodo `.predict` de su modelo. \n",
        "\n",
        "¿Qué tan bien se desempeñaría su modelo en un caso real en vista de lo anterior? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bd-nauiX04A"
      },
      "outputs": [],
      "source": [
        "# . . ."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}